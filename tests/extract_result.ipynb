{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/admin01/Data/BBSEA-sapien/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config.core import dataset_path, prompts_dir\n",
    "from llm_interaction.request import gpt_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8, 1.0, 0.6]\n"
     ]
    }
   ],
   "source": [
    "def extract_pre_scene_graph(lines):\n",
    "    pre_scene_graph_lines = []\n",
    "    inside_pre_scene_graph = False\n",
    "\n",
    "    for line in lines:\n",
    "        if \"pre scenegraph:\" in line:\n",
    "            inside_pre_scene_graph = True\n",
    "            continue\n",
    "        if \"post scenegraph:\" in line:\n",
    "            break\n",
    "        if inside_pre_scene_graph:\n",
    "            pre_scene_graph_lines.append(line)\n",
    "\n",
    "    return ''.join(pre_scene_graph_lines)\n",
    "\n",
    "\n",
    "task_list = os.listdir(dataset_path)\n",
    "task_list.remove(\"result.json\")\n",
    "task_list.sort(key=lambda x : int(x.split('_')[1]))\n",
    "\n",
    "task_decomposition_records=[]\n",
    "\n",
    "for task in task_list:\n",
    "    task_decomposition_record={}\n",
    "\n",
    "    with open(os.path.join(dataset_path, task, \"description.txt\"), 'r') as f:\n",
    "        task_log = f.readlines()\n",
    "        task_decomposition_record[\"task_description\"]=task_log[1].strip()\n",
    "        task_decomposition_record[\"task_pre_SG\"]=extract_pre_scene_graph(task_log)\n",
    "\n",
    "    subtask_list = os.listdir(os.path.join(dataset_path, task))\n",
    "    subtask_list.remove(\"description.txt\")\n",
    "    subtask_list.sort(key=lambda x : int(x.split('_')[1]))\n",
    "    \n",
    "    subtask_descriptions=[]\n",
    "    for subtask in subtask_list:\n",
    "        with open(os.path.join(dataset_path, task, subtask, \"description.txt\"), 'r') as f:\n",
    "            subtask_log = f.readlines()\n",
    "            subtask_description = subtask_log[1].strip()\n",
    "            subtask_descriptions.append(subtask_description)\n",
    "\n",
    "    task_decomposition_record[\"subtask_descriptions\"]=subtask_descriptions\n",
    "\n",
    "    task_decomposition_records.append(task_decomposition_record)\n",
    "\n",
    "\n",
    "with open(os.path.join(prompts_dir, \"task_decomposition_quality_w_SG.txt\"), \"r\") as f:\n",
    "    base_prompt = f.read()\n",
    "\n",
    "Scores=[]\n",
    "multi_task_decomposition_prompt=\"\"\n",
    "for task_decomposition_record in task_decomposition_records:\n",
    "    single_task_decomposition_prompt=\\\n",
    "    \"Scene Description:\\n{}\\n\\nMajor Task:\\n{}\\n\\nTask Decomposition:\\n{}\\n\\nPlease provide a score (1-5) based on the task decomposition above, considering the scene description, and briefly explain your reasoning.\\n\"\n",
    "\n",
    "    multi_task_decomposition_prompt+=single_task_decomposition_prompt.format(\n",
    "        task_decomposition_record[\"task_pre_SG\"], \n",
    "        task_decomposition_record[\"task_description\"], \n",
    "        task_decomposition_record[\"subtask_descriptions\"]\n",
    "    )\n",
    "\n",
    "task_decomposition_quality_prompt = base_prompt.format(multi_task_decomposition_prompt)\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': [\n",
    "            {\"type\":\"text\", \"text\": task_decomposition_quality_prompt},\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "response = gpt_api(messages, 0.2, model='4o')\n",
    "\n",
    "scores = re.findall(r'Score: (\\d)/5', response)\n",
    "scores_as_floats = [float(score)/5 for score in scores]\n",
    "\n",
    "print(scores_as_floats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1937\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(len(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7666666666666667\n",
      "0.7999999999999999\n"
     ]
    }
   ],
   "source": [
    "a=[0.6, 1.0, 0.8, 0.8, 1.0, 0.4]\n",
    "print(sum(a)/len(a))\n",
    "\n",
    "a=[0.6, 1.0, 0.8, 0.8, 1.0, 0.6]\n",
    "print(sum(a)/len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6666666666666669\n",
      "0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "a=[0.6, 0.8, 0.8, 0.6, 0.8, 0.4]\n",
    "print(sum(a)/len(a))\n",
    "\n",
    "a=[0.6, 0.8, 1.0, 0.6, 0.8, 0.6]\n",
    "print(sum(a)/len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        'role': 'user',\n",
    "        'content': [\n",
    "            {\"type\":\"text\", \"text\": task_decomposition_quality_prompt},\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "response = gpt_api(messages, 0.2, model='4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```\n",
      "Score: 4/5\n",
      "Reason:\n",
      "- Logical Coherence: The task decomposition is logically coherent. It clearly separates the toys, kitchen items, and the power drill into distinct areas on the table.\n",
      "- Detailing: The smaller tasks are clear and specific, detailing exactly which items need to be moved and to which part of the table.\n",
      "- Goal Achievement: The tasks effectively achieve the major goal of organizing the items into their respective categories and areas on the table.\n",
      "- Consideration of Spatial Relationships: The task considers spatial relationships well by grouping similar items together and placing the power drill in a separate area. However, it could be improved by specifying the exact positions within the right side or center of the table for better clarity.\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"\"\"\n",
    "Score: 4/5\n",
    "Reason:\n",
    "- Logical Coherence: The task decomposition is logically coherent. It clearly separates the toys, kitchen items, and the power drill into distinct areas on the table.\n",
    "- Detailing: The smaller tasks are clear and specific, detailing exactly which items need to be moved and to which part of the table.\n",
    "- Goal Achievement: The tasks effectively achieve the major goal of organizing the items into their respective categories and areas on the table.\n",
    "- Consideration of Spatial Relationships: The task considers spatial relationships well by grouping similar items together and placing the power drill in a separate area. However, it could be improved by specifying the exact positions within the right side or center of the table for better clarity.\n",
    "\"\"\"\n",
    "\n",
    "# Regular expression to extract score\n",
    "match = re.search(r'Score: (\\d+)/(\\d+)', text)\n",
    "if match:\n",
    "    score = float(match.group(1)) / float(match.group(2))\n",
    "    print(f\"Score: {score}\")\n",
    "else:\n",
    "    print(\"Score not found\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "roboSim",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
